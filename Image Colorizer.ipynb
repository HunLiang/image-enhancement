{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lR4SIN6kU9VF"
   },
   "outputs": [],
   "source": [
    "#uncomment this line if you get import errors\n",
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S46fXu9OolIZ"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import models, layers\n",
    "import tensorflowjs as tfjs\n",
    "import zipfile\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWSxboyhcTCi"
   },
   "source": [
    "The following three code cells involve loading the images, converting them to the Lab and greyscale colorspaces, and dividing them into testing and training feature/label sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o7QgqWeVo7--"
   },
   "outputs": [],
   "source": [
    "#return the set of grayscale and color images from the given filepath\n",
    "def getData(filepath):\n",
    "  rgb_list = []\n",
    "  gray_list = []\n",
    "  file_path = glob.glob(os.path.join(filepath,'*.jpg'))\n",
    "\n",
    "  for img_path in file_path:\n",
    "    rgb_img = cv2.imread(img_path) #take in the BGR image in the form of a numpy array\n",
    "    gray_img = cv2.cvtColor(rgb_img, cv2.COLOR_BGR2GRAY) #convert to grayscale using cv2\n",
    "\n",
    "    rgb_img = cv2.cvtColor(rgb_img, cv2.COLOR_BGR2LAB)\n",
    "    rgb_img = cv2.resize(rgb_img,(224,224))\n",
    "    gray_img = cv2.resize(gray_img,(224,224))\n",
    "    rgb_list.append(rgb_img)\n",
    "    gray_list.append(gray_img)\n",
    "\n",
    "  rgb_images = np.stack(rgb_list,axis=0)\n",
    "  gray_images = np.stack(gray_list,axis=0)\n",
    "  gray_images = np.reshape(gray_images,(len(gray_images),224,224,1))\n",
    "\n",
    "  #print(np.shape(rgb_images),np.shape(gray_images))\n",
    "  return rgb_images , gray_images\n",
    "\n",
    "#combine L and ab channels into a single image\n",
    "def combineLab(L, ab):\n",
    "  outLab = np.empty((224, 224, 3))\n",
    "  outLab[:, :, 1:3] = ab\n",
    "  outLab[:, :, 0] = L.reshape(224, 224)\n",
    "  #outLab[:, :, 0] = np.full((224, 224), .5)\n",
    "  outLab = (outLab * 255).astype(np.uint8);\n",
    "  return cv2.cvtColor(outLab, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "#resize image\n",
    "def resize(filepath):\n",
    "  in_path = glob.glob(os.path.join(filepath,'*.jpg'))\n",
    "  for i in range(0, len(in_path)):\n",
    "    rgb_img = cv2.imread(in_path[i]) #take in the BGR image in the form of a numpy array\n",
    "    rgb_img = cv2.resize(rgb_img,(224,224))\n",
    "    cv2.imwrite(in_path[i], rgb_img)\n",
    "\n",
    "#resize(\"drive/MyDrive/ML/landscapes_some\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SjZzv6_emNn"
   },
   "outputs": [],
   "source": [
    "with ZipFile('landscapes2000.zip', 'r') as zipObj:\n",
    "  zipObj.extractall('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5483,
     "status": "ok",
     "timestamp": 1641576523800,
     "user": {
      "displayName": "Ethan James",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14113693362490470948"
     },
     "user_tz": 300
    },
    "id": "4s4fy_33rhnB",
    "outputId": "e6526746-3893-476f-efa2-39f922bd611b"
   },
   "outputs": [],
   "source": [
    "#prepare features and labels (inputs and outputs, respectively)\n",
    "training_labels, training_features = getData(\"training\")\n",
    "training_labels = training_labels / 255.\n",
    "training_features = training_features / 255.;\n",
    "\n",
    "testing_labels, testing_features = getData(\"testing\")\n",
    "testing_labels = testing_labels / 255.\n",
    "testing_features = testing_features / 255.;\n",
    "\n",
    "#chop the L component off the Lab image to leave just the ab components\n",
    "training_labels = training_labels[:, :, :, 1:3]\n",
    "testing_labels = testing_labels[:, :, :, 1:3]\n",
    "\n",
    "training_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwa7ifQqcmfv"
   },
   "source": [
    "The following cells set up the model, train it, evaluate it using testing data, and show a sample with one image in the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2899,
     "status": "ok",
     "timestamp": 1641576526689,
     "user": {
      "displayName": "Ethan James",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14113693362490470948"
     },
     "user_tz": 300
    },
    "id": "U1DYMXmXvQdF",
    "outputId": "b7cc8ae0-c4b0-42eb-bd1f-16824e296ab3"
   },
   "outputs": [],
   "source": [
    "#create the model used for colorizing images\n",
    "input_layer = layers.Input(shape=(224,224,1))\n",
    "encoder_layer = layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same')(input_layer)\n",
    "encoder_layer = layers.MaxPooling2D((2, 2), padding='same')(encoder_layer)\n",
    "encoder_layer = layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same')(encoder_layer)\n",
    "encoder_layer = layers.MaxPooling2D((2, 2), padding='same')(encoder_layer)\n",
    "encoder_layer = layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same')(encoder_layer)\n",
    "encoder_layer = layers.MaxPooling2D((2, 2), padding='same')(encoder_layer)\n",
    "encoder_layer = layers.Conv2D(256, (3, 3), activation = 'relu', padding = 'same')(encoder_layer)\n",
    "encoder_layer = layers.MaxPooling2D((2, 2), padding='same')(encoder_layer)\n",
    "\n",
    "decoder_layer = layers.UpSampling2D((2, 2))(encoder_layer)\n",
    "decoder_layer = layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same')(decoder_layer)\n",
    "decoder_layer = layers.UpSampling2D((2, 2))(decoder_layer)\n",
    "decoder_layer = layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same')(decoder_layer)\n",
    "decoder_layer = layers.UpSampling2D((2, 2))(decoder_layer)\n",
    "decoder_layer = layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same')(decoder_layer)\n",
    "decoder_layer = layers.UpSampling2D((2, 2))(decoder_layer)\n",
    "decoder_layer = layers.Conv2D(16, (3, 3), activation = 'relu', padding = 'same')(decoder_layer)\n",
    "output_layer = layers.Conv2D(2, (3, 3), padding = 'same', activation = 'sigmoid')(decoder_layer)\n",
    "\n",
    "model = models.Model(input_layer, output_layer)\n",
    "model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 205652,
     "status": "ok",
     "timestamp": 1641576732338,
     "user": {
      "displayName": "Ethan James",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14113693362490470948"
     },
     "user_tz": 300
    },
    "id": "Eu9ItDXix89x",
    "outputId": "44f8da8c-b805-4223-9aa0-407d0f2d600e"
   },
   "outputs": [],
   "source": [
    "#train and save the model.\n",
    "#If desired, the top two lines can be commented out and the 3rd line \n",
    "#uncommented to load an existing model, as opposed to training a new model.\n",
    "model.fit(training_features, training_labels, batch_size=32, epochs=10)\n",
    "model.save('landscapes.keras')\n",
    "tfjs.converters.save_keras_model(model, 'landscapes.json') #btw, I added this line for exporting the model to js. Comment this out if you're loading an existing model\n",
    "#model = models.load_model('landscapes35.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10513,
     "status": "ok",
     "timestamp": 1641576742841,
     "user": {
      "displayName": "Ethan James",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14113693362490470948"
     },
     "user_tz": 300
    },
    "id": "x7NTUl8kjxp2",
    "outputId": "e6061d8b-63ad-4a61-ef69-215bb20f0119"
   },
   "outputs": [],
   "source": [
    "#evaluate the model with both the training and testing data\n",
    "model.evaluate(training_features, training_labels)\n",
    "model.evaluate(testing_features, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "executionInfo": {
     "elapsed": 2941,
     "status": "ok",
     "timestamp": 1641576802548,
     "user": {
      "displayName": "Ethan James",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14113693362490470948"
     },
     "user_tz": 300
    },
    "id": "LWx8H-B63K5F",
    "outputId": "7fae3d44-7b6a-4dc8-a116-c8ca8cbcfe30"
   },
   "outputs": [],
   "source": [
    "#test out the model with a specific image (at index n)\n",
    "n = 28\n",
    "greyscale = testing_features[n]\n",
    "out = model.predict(testing_features[n].reshape(1, 224, 224, 1))\n",
    "original = testing_labels[n]\n",
    "\n",
    "plt.figure(figsize=(12, 4), dpi=100)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(greyscale.reshape(224, 224), cmap='gray')\n",
    "plt.subplot(1, 3, 2)\n",
    "\n",
    "plt.imshow(combineLab(greyscale, out))\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(combineLab(greyscale, original))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Image Colorizer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
